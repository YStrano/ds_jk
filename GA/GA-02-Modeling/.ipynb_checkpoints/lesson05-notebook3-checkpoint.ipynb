{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Methods\n",
    "\n",
    "- Feature Scaling\n",
    "- Test/Train split\n",
    "- Ridge, LASSO, Elastic Net Regression methods\n",
    "\n",
    "---\n",
    "\n",
    "In a regular linear scenario, we start with a regular linear function.\n",
    "\n",
    "$$ \\hat y = b + ax_0$$\n",
    "\n",
    "\n",
    "\n",
    "The mean square error of these predictions would be given by:\n",
    "\n",
    "$$RSS(a, b) = \\sum_{i = 1}^n(y_i -  (ax_i + b))^2$$\n",
    "\n",
    "From this basic $MSE$ formulation, we can introduce some Regularized methods that add a *regularization term*  to the $MSE$.  We will look at three methods that offer slight variations on this term.\n",
    "\n",
    "### Feature Scaling\n",
    "\n",
    "To use these methods, we want to scale our data.  Many Machine Learning algorithms don't do well with data operating on very different scales.  Using the `MinMaxScaler` normalizes the data and brings the values between 0 and 1. The `StandardScaler` method is less sensitive to wide ranges of values. We will use both on our Ames housing data.  To begin, we need to select the numeric columns from the DataFrame so we can transform them only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get our data and select the numer\n",
    "ames = pd.read_csv('data/ames_housing.csv')\n",
    "y = ames['SalePrice']\n",
    "ames = ames.drop('SalePrice', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_numeric = ames.select_dtypes(include = 'int64')\n",
    "ames_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Scaler on a DataFrame\n",
    "\n",
    "Below, we can compare the results of the two scaling transformations by passing a list of column names to the scaler.  Note the practice of initializing the object, fitting it, and transforming.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaled = StandardScaler()\n",
    "minmax_scaled = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ames_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = std_scaled.fit_transform(ames[[name for name in cols]])\n",
    "minmax_df = minmax_scaled.fit_transform(ames[[name for name in cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(std_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(minmax_df).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Linear Model on Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_numeric_scaled = std_scaled.fit_transform(ames[[name for name in cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(ames_numeric_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(ames_numeric_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "score = lm.score(ames_numeric_scaled, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R-squared score: {}'.format(score), '\\nRMSE: {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data \n",
    "\n",
    "As we have seen, we will tend to overfit the data if we use the entire dataset to determine the model.  To account for this, we will split our datasets into a **training set** to build our model on, and a **test set** to evaluate the performance of the model.  We have a handy sklearn method for doing this, who by default splits the data into 80% for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ames_numeric_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Methods Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime = pd.read_csv('data/crime_data.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = crime['ViolentCrimesPerPop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = crime.drop('ViolentCrimesPerPop', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train_scaled, y_train)\n",
    "predictions = lm.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "score = lm.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "$$RSS(w, b) = \\sum_{i = 1} ^ N (y_i - (wx_i + b))^2 + \\alpha \\sum_{j = 1}^p w_j^2 $$\n",
    "\n",
    "Many feature coefficients will be determined with small values.  Larger $\\alpha$ means larger penalty, zero is base LinearRegression, and the default for sklearn's implementation is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha = 1, solver = \"cholesky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpred = ridge_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, rpred))\n",
    "score = ridge_reg.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(ridge_reg.coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(alpha = 20, solver = \"cholesky\")\n",
    "ridge_reg.fit(X_train_scaled, y_train)\n",
    "rpred = ridge_reg.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, rpred))\n",
    "score = ridge_reg.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "\n",
    "$$RSS(w, b) = \\sum_{i = 1} ^ N (y_i - (wx_i + b))^2 + \\alpha \\sum_{j = 1}^p |w_j| $$\n",
    "\n",
    "Now, we end up in effect setting variables with low influence to a coefficient of zero.  Compared to Ridge, we would use Lasso if there are only a few variables with substantial effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso(alpha = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpred = lasso_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, lpred))\n",
    "score = ridge_reg.score(X_test_scaled, y_test)\n",
    "print('The r2 value is : {:.4f}'.format(score), '\\nThe RMSE value is {:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(lasso_reg.coef_ != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in sorted (list(zip(list(X), lasso_reg.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net\n",
    "\n",
    "$$RSS(w, b) = \\sum_{i = 1} ^ N (y_i - (wx_i + b))^2 + r\\alpha\\sum_{i = 1}^n |w_j| + \\frac{1-r}{2} \\alpha \\sum_{j = 1}^p w_j^2 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_reg = ElasticNet(alpha = .05, l1_ratio=0.4)\n",
    "elastic_reg.fit(X_train_scaled, y_train)\n",
    "epred = elastic_reg.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, epred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_score = ridge_reg.score(X_test_scaled, y_test)\n",
    "lasso_score = lasso_reg.score(X_test_scaled, y_test)\n",
    "elastic_score = elastic_reg.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge: {:.4f}\".format(ridge_score), \"\\nLasso: {:.4f}\".format(lasso_score),\n",
    "      \"\\nElastic Net: {:.4f}\".format(elastic_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM\n",
    "\n",
    "Return to your Ames Data.  We have covered a lot of ground today, so let's summarize the things we could do to improve the performance of our original model that compared the Above Ground Living Area to the Logarithm of the Sale Price.\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "1. Clean data, drop missing values\n",
    "2. Transform data, code variables using either ordinal values or OneHotEncoder methods\n",
    "3. Create more features from existing features\n",
    "4. Split our data into testing and training sets\n",
    "5. Normalize quantitative features\n",
    "6. Use Regularized Regression methods and Polynomial regression to improve performance of model\n",
    "</div>\n",
    "Can you use some or all of these ideas to improve upon your initial model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "\n",
    "The last two lessons have pulled heavily from these resources.  I recommend them all strongly as excellent resources:\n",
    "\n",
    "- SciKitLearn documentation on Regression: http://scikit-learn.org/stable/supervised_learning.html#supervised-learning\n",
    "\n",
    "- Aurelien Geron, *Hands on Machine Learning with SciKitLearn and TensorFlow*\n",
    "\n",
    "- James et. al, *An Introduction to Statistical Learning: With Applications in R*\n",
    "\n",
    "- Philipp K. Janert, *Data Analysis with OpenSource Tools*\n",
    "\n",
    "- University of Michigan Coursera Class on Machine Learning with SciKitLearn: https://www.coursera.org/learn/python-machine-learning\n",
    "\n",
    "- Stanford University course on Machine Learning: https://www.coursera.org/learn/machine-learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
