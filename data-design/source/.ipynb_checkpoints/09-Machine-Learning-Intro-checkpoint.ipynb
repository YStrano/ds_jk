{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with NLTK\n",
    "\n",
    "http://www.nltk.org/api/nltk.sentiment.html\n",
    "\n",
    "https://www.kaggle.com/ngyptr/python-nltk-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subj_docs), len(obj_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['color',\n",
       "  ',',\n",
       "  'musical',\n",
       "  'bounce',\n",
       "  'and',\n",
       "  'warm',\n",
       "  'seas',\n",
       "  'lapping',\n",
       "  'on',\n",
       "  'island',\n",
       "  'shores',\n",
       "  '.',\n",
       "  'and',\n",
       "  'just',\n",
       "  'enough',\n",
       "  'science',\n",
       "  'to',\n",
       "  'send',\n",
       "  'you',\n",
       "  'home',\n",
       "  'thinking',\n",
       "  '.'],\n",
       " 'subj')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj_docs = subj_docs[:80]\n",
    "test_subj_docs = subj_docs[80:]\n",
    "train_obj_docs = obj_docs[:80]\n",
    "test_obj_docs = obj_docs[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = train_subj_docs + train_obj_docs\n",
    "test_docs = test_obj_docs + test_subj_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SentimentAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_neg = clf.all_words([mark_negation(doc) for doc in train_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_features = clf.unigram_word_feats(all_words_neg, min_freq = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.add_feat_extractor(extract_unigram_feats, unigrams = unigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = clf.apply_features(train_docs)\n",
    "test_set = clf.apply_features(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = NaiveBayesClassifier.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "classifier = clf.train(trainer, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.8\n",
      "F-measure [obj]: 0.8\n",
      "F-measure [subj]: 0.8\n",
      "Precision [obj]: 0.8\n",
      "Precision [subj]: 0.8\n",
      "Recall [obj]: 0.8\n",
      "Recall [subj]: 0.8\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(clf.evaluate(test_set).items()):\n",
    "     print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example\n",
    "\n",
    "Below is a similar problem with some food review data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [(\"Great place to be when you are in Bangalore.\", \"pos\"),\n",
    "  (\"The place was being renovated when I visited so the seating was limited.\", \"neg\"),\n",
    "  (\"Loved the ambience, loved the food\", \"pos\"),\n",
    "  (\"The food is delicious but not over the top.\", \"neg\"),\n",
    "  (\"Service - Little slow, probably because too many people.\", \"neg\"),\n",
    "  (\"The place is not easy to locate\", \"neg\"),\n",
    "  (\"Mushroom fried rice was spicy\", \"pos\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = set(word.lower() for passage in train for word in word_tokenize(passage[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = set(word.lower() for passage in train for word in word_tokenize(passage[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in dictionary}, x[1]) for x in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "test_data = \"Manchurian was hot and spicy\"\n",
    "test_data_features = {word.lower(): (word in word_tokenize(test_data.lower())) for word in dictionary}  \n",
    "print (classifier.classify(test_data_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Vader\n",
    "\n",
    "There is an additional tool for sentiment analysis built in to nltk that includes another sentiment analysis analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"It was one of the worst movies I've seen, despite good reviews. Unbelievably bad acting!! Poor direction. VERY poor production. The movie was bad. Very bad movie. VERY bad movie. VERY BAD movie. VERY BAD movie!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_list = tokenize.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It was one of the worst movies I've seen, despite good reviews.\",\n",
       " 'Unbelievably bad acting!!',\n",
       " 'Poor direction.',\n",
       " 'VERY poor production.',\n",
       " 'The movie was bad.',\n",
       " 'Very bad movie.',\n",
       " 'VERY bad movie.',\n",
       " 'VERY BAD movie.',\n",
       " 'VERY BAD movie!']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was one of the worst movies I've seen, despite good reviews.\n",
      "compound: -0.7584, neg: 0.394, neu: 0.606, pos: 0.0, \n",
      "Unbelievably bad acting!!\n",
      "compound: -0.6572, neg: 0.686, neu: 0.314, pos: 0.0, \n",
      "Poor direction.\n",
      "compound: -0.4767, neg: 0.756, neu: 0.244, pos: 0.0, \n",
      "VERY poor production.\n",
      "compound: -0.6281, neg: 0.674, neu: 0.326, pos: 0.0, \n",
      "The movie was bad.\n",
      "compound: -0.5423, neg: 0.538, neu: 0.462, pos: 0.0, \n",
      "Very bad movie.\n",
      "compound: -0.5849, neg: 0.655, neu: 0.345, pos: 0.0, \n",
      "VERY bad movie.\n",
      "compound: -0.6732, neg: 0.694, neu: 0.306, pos: 0.0, \n",
      "VERY BAD movie.\n",
      "compound: -0.7398, neg: 0.724, neu: 0.276, pos: 0.0, \n",
      "VERY BAD movie!\n",
      "compound: -0.7616, neg: 0.735, neu: 0.265, pos: 0.0, \n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "for sent in lines_list:\n",
    "    print(sent)\n",
    "    ss = sid.polarity_scores(sent)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end = '')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
