{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Design with Python\n",
    "\n",
    "**OVERVIEW**\n",
    "\n",
    "This short course aims to introduce participants to the Python computing language.  We will investigate the use of Python to perform data analysis, access and structure information from the web, and build and deploy applications like web pages and message boards using Django.  Students will be expected to complete a small project for each weeks topics described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Material Locations\n",
    "\n",
    "- **Course Documentation**:  http://data-and-design.readthedocs.io/en/latest/\n",
    "- **Github Repository**: https://github.com/jfkoehler/data-design/tree/master/source\n",
    "- **Slack Channel**: https://datadesignpython.slack.com/\n",
    "- **YouTube Channel**: https://www.youtube.com/playlist?list=PLUCTTwyv9AdUYtNeV5w-2xMX5O9cCcfkB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics\n",
    "\n",
    "- **Introduction to Data and Visualizations**: The first class will focus on using Pandas and Seaborn to explore data in `.csv` files and through API's.  We emphasize the use of the computer to explore the data and look for patterns and differences.  Our first project involves writing an analysis of New York City's $8^{\\text{th}}$ grade mathematics scores.\n",
    "\n",
    "   - [Introduction to Pandas and Seaborn](02-introPandas.ipynb)\n",
    "   - [Pandas and Seaborn](03-datafiles.ipynb)\n",
    "   - [Assignment: Access and Analyze Data](04-ProjectA.ipynb)\n",
    "   \n",
    "- **Introduction to Web Scraping**: Today, we investigate the use of webscraping to pull and clean data from websites.  We will investigate some basics of HTML and CSS, and use the `requests` and `BeautifulSoup2` libraries to pull this information.\n",
    "\n",
    "  - [Introduction to webscraping](05-intro_to_scraping_I.ipynb)\n",
    "  - [Scraping Part II](07-scraping-jumpstreet.ipynb)\n",
    "  \n",
    "- **Natural Language Processing and Scraping**: Today, we extend our webscraping work to analyze the text of documents scraped.  We will use the Natural Language Toolkit to analyze text.  We will also introduce the use of regular expressions in navigating text on the computer.\n",
    "\n",
    "  - [Webscraping and Natural Language Processing](08_scraping_and_nltk.ipynb)\n",
    "  - [Sentiment Analysis of Text](09-Machine-Learning-Intro.ipynb)\n",
    "  - [More Machine Learning](09_ML_Intro.ipynb)\n",
    "  \n",
    "- **Web Design with Django**: In this workshop, we will use the Django framework to design and deploy a basic web application.  Our assignment will be a basic website ready to display our earlier work with Jupyter notebooks.  We discuss Django projects and applications to use Python to build a basic website.\n",
    "\n",
    "  - [Basic WebSite with Django](11-django-intro.ipynb)\n",
    "  - [Applications with Django](12-Django-templates.ipynb)\n",
    "\n",
    "  \n",
    "- **Data and our Website**: The final class serves to connect our earlier work with data and Python through Django models, where we build a database for our website.  We will add a Blog application to our site, post some information, and access these posts as data in the shell.  Finally, we use the ListView and DetailView to display these posts together with template logic.\n",
    "\n",
    "  - [Databases and Django: A Basic Blog](13-Django-Models-Blogs.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lessons Learned\n",
    "\n",
    "- **Student Computers**: A number of students experienced difficulties with their computers at different points during the semester.  In the first weeks, students who lacked access to their own functioning laptops dropped from enrollment.  Also, a few students who were unaware of the level of coding involved dropped the course.  If we were able to identify an IT support person who is capable of helping students install and optimize their personal computers, this would be great.\n",
    "\n",
    "### Technology Work\n",
    "\n",
    "Also, if we were able to provide a web-based coding environment this could alleviate many of these issues.  Below are three such options:\n",
    "\n",
    "- **OpenEdX**: A Learning Management system built by MIT and Harvard as part of their opencourse initiatives.  This is freely available, however we would need a person competent in full stack web development.  Alternatively, third party companies will launch and manage these applications for a fee that based on my initial research would be in the \\$10,000 neighborhood.\n",
    "\n",
    "- **CoCalc**: A collaborative computing platform that has many language capability.  We should be able to launch some version of this ourselves, using the Jupyter notebook and text editor execution capabilities of the service.  This would again require some support from an individual who understands servers and deploying interactive software applications on them.  \n",
    "\n",
    "- **JupyterHub**: There have been examples of institutions that integrate Jupyter notebooks and other code related interfaces into their Learning Management Systems through JupyterHub.  The most popular example is the Data8 course at UC Berkeley.\n",
    "\n",
    "   - http://data8.org/\n",
    "   \n",
    "    This class integrates the JupyterHub with a virtual textbook.  I am close to such things however I don't have full control over my JupyterHub.  \n",
    "    \n",
    "    You can check it out at \n",
    "\n",
    "   - http://hub.dubmathematics.com\n",
    "   \n",
    "My goal is to integrate this within a website that students can access using some kind of login token.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggestions for Course\n",
    "\n",
    "Despite some bumps in the road, many students were able to complete excellent work.  Here are some examples of student github repositories that house three projects and a completed website built with Django:\n",
    "\n",
    "- https://github.com/charmillz/datadesign_python\n",
    "- https://github.com/jchan9/Data_Design_Python/tree/master/Data/Projects\n",
    "- https://github.com/warpz785/data-design\n",
    "- https://github.com/kyler-ross/git-test\n",
    "\n",
    "If I were to do the course over again, I would keep the aim for work with both Data Analysis and Web Design as the focus.  Ideally, the class would be a regular 3 or 4 hour class where we can spend more time on all three areas.  I would also be interested in connecting with other instructors who work in web design and data visualization to normalize the use of specific technologies.\n",
    " \n",
    " -----\n",
    "\n",
    "### Hypothetical Semester Length Version\n",
    "\n",
    "\n",
    "Here is a prospective outline for such a class:\n",
    "\n",
    "#### Section I: Data Analysis and Machine Learning\n",
    "\n",
    "- **Week I**: Introduction to Python \n",
    "\n",
    "Base introduction to the Python language.  Jupyter notebooks and plotting.  Saving and reusing programs.\n",
    "\n",
    "- **Week II**: Introduction to Pandas\n",
    "\n",
    "Introduction to Data Structures and the Pandas library.  Students will work with built in and external datasets.  \n",
    "\n",
    "- **Week III**: Introduction to Machine Learning\n",
    "\n",
    "We introduce machine learning through the Regression and Clustering algorithms.  We will see how to implement each of these algorithms on our data structured with Pandas.\n",
    "\n",
    "- **Week IV**: Machine Learning with TensorFlow\n",
    "\n",
    "In this week, we introduce applications of machine learning to visual and audio problems with the Google TensorFlow machine learning library.  Here we will discuss neural networks and their use in solving computer vision problems.  \n",
    "\n",
    "#### Section II: Data and the Internet\n",
    "\n",
    "- **Week VI**: Introduction to WebScraping\n",
    "\n",
    "This week focuses on data accession from the web.  To start, we will scrape numerical tables into a Pandas DataFrame and use our earlier work with visualization and data analysis to explore the web data.  Next we will focus on accessing and structuring textual data from tables in Wikipedia articles.\n",
    "\n",
    "- **Week VII**: WebCrawling\n",
    "\n",
    "This week we will use Scrapy to set up a web crawler that will extract data from multiple websites with a similar structure.  \n",
    "\n",
    "- **Week VIII**: Natural Language Processing I\n",
    "\n",
    "Building on our earlier work with data analysis, we start turn text into data using the NLTK library.  We discuss some introductory Natural Language Processing techniques and visualize novels from Project Gutenberg.  \n",
    "\n",
    "- **Week IX**: Machine Learning and Text\n",
    "\n",
    "This week we focus on using Machine Learning to understand the sentiment and important topics in a range of text.  This will take place with reviews on Yelp and Amazon.com.\n",
    "\n",
    "#### Section III: Web Design with Django\n",
    "\n",
    "- **Week X**: Introduction to Django\n",
    "\n",
    "Setup a basic static website using the Python web framework Django.\n",
    "We will discuss the basics of how the internet works and complete a basic website that contains static HTML files that include some basic p5.js animations.\n",
    "\n",
    "- **Week XI**: Django and Models\n",
    "\n",
    "The week we explore the use of databases with Django applications.  We will build a blog for our site and begin to post entries based on our eariler projects.  Next, we see how we can analyze this data using our Juptyer notebooks.\n",
    "\n",
    "- **Week XII**: Serving our Site\n",
    "\n",
    "This week we complete our work with styling the basic site and serve it live to the internet using the Heroku service.  \n",
    "\n",
    "\n",
    "- **Week XIII**: User Authentication and Site Access\n",
    "\n",
    "Adding to our website, we build a user authentication interface that allows us to restrict access to all or part of our website.\n",
    "\n",
    "- **Week XIV**: Packaging your site as a reusable application\n",
    "\n",
    "Finally, we will package our site for public use.  We will use the Python standards to share our work with the larger world, including the launching of our frameworks on their own computer using a simple `pip install`.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
